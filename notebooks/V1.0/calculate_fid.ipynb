{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate Fréchet Inception Distance (FID) Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "import fid\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FID\n",
    "\n",
    "The FID score was introduced by Heusel et al. (2017, see: https://arxiv.org/abs/1706.08500 ) in order to improve on the currently established inception score (IS) for the evaluation of image generation DL methods, specifically when applying GAN architectures. FID - in comparison to IS - has the ability to evaluate the quality of generated images by comparing a statistical distribution of a latent representation feature vector based on the InceptionV3 model with the same same statistical distribution of the original images.\n",
    "\n",
    "FID achieves this by using the Fréchet distance between the two distributions representing the real and generated images as follows:\n",
    "\n",
    "<div align=\"center\">\n",
    "    <img src=\"FID.PNG\"></img><br>\n",
    "    <i>source: https://jonathan-hui.medium.com/gan-how-to-measure-gan-performance-64b988c47732</i>\n",
    "</div>\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "where:<br>\n",
    "    x = real images<br>\n",
    "    g = generated images<br>\n",
    "    µx = mean of the multivariate Gaussian distribution representing the latent vector of real images<br>\n",
    "    µg = mean of the multivariate Gaussian distribution representing the latent vector of generated images<br>\n",
    "    Σx = covariance matrix for real images<br>\n",
    "    Σg = covariance matrix for generated images<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essentially, calculating a FID score for two sets of images requires the following steps:\n",
    "\n",
    "1. Load <i>Inception V3</i> model\n",
    "2. Modify <i>Inception V3</i> so that we discard the output layer (classification into image categories), only keeping a max pooling layer representing the latent space vector.\n",
    "3. Calculate the <i>mean (µ)</i> and <i>variance (Σ)</i> based on the latent space vector of the real (training) images\n",
    "4. Generate images (here using a GAN)\n",
    "5. Calculate the <i>mean (µ)</i> and <i>variance (Σ)</i> based on the latent space vector of the generated (\"fake\") images\n",
    "6. Calculate FID based on Fréchet Distance between the two statistical distributions\n",
    "\n",
    "Luckily the implementation provided by the paper's authors takes care of step 1. and 2., so here we start with step 3.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate Training Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 726300 files belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "# implementation by authors preloads all images to RAM to calculate real distribution parameters. with 700'000 images this is not possible.\n",
    "# I may have to custom implement a FID network based on Inception V3 by removing the last layer (see: https://machinelearningmastery.com/how-to-implement-the-frechet-inception-distance-fid-from-scratch/)\n",
    "inception_path = fid.check_or_download_inception(None)\n",
    "fid.create_inception_graph(inception_path) \n",
    "\n",
    "\n",
    "# load training dataset (full)\n",
    "IMAGE_SIZE = (1024, 1024)\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "data_dir = pathlib.Path('/data/input/crops')\n",
    "imgs = list(data_dir.glob('*.png'))\n",
    "\n",
    "dataset_train = tf.keras.preprocessing.image_dataset_from_directory(  '/data/input/',\n",
    "                                                                      image_size=IMAGE_SIZE, \n",
    "                                                                      batch_size=BATCH_SIZE, \n",
    "                                                                      labels=[1.] * len(imgs), # setting all labels to 1 (for 'real')\n",
    "                                                                      #label_mode=None, # yields float32 type labels\n",
    "                                                                      seed=42\n",
    "                                                                    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset_train)\n",
    "for i in dataset_train.take(1):\n",
    "    print(i)\n",
    "    if i == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'Session'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-948490462709>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_inception_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minception_path\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# load the graph into the current TF graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmu_gen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_activation_statistics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'Session'"
     ]
    }
   ],
   "source": [
    "fid.create_inception_graph(inception_path)  # load the graph into the current TF graph\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    mu_gen, sigma_gen = fid.calculate_activation_statistics(dataset_train, sess, batch_size=BATCH_SIZE)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
